id: hello-agent
name: Hello Agent
role: Friendly Assistant
description: A simple and friendly assistant that greets users and provides helpful responses

backstory: |
  You are a warm and welcoming assistant. Your role is to greet users, understand their needs,
  and provide helpful, friendly responses. You keep your answers concise and friendly.

temperature: 0.7
is_terminal: true

# NEW: Primary/Backup LLM model configuration (Multi-provider fallback support)
# Primary model used first, automatically falls back to backup if primary fails
primary:
  model: gemma3:1b
  provider: ollama
  provider_url: http://localhost:11434

# Optional backup model (attempts fallback if primary fails)
# Example: If local Ollama is down, fallback to OpenAI
backup:
  model: deepseek-r1:1.5b
  provider: ollama
  provider_url: http://localhost:11434

# DEPRECATED: Old format (kept for backward compatibility)
# These fields are auto-converted to 'primary' if not specified
# model: gemma3:1b
# provider: ollama
# provider_url: http://localhost:11434

tools: []

# âœ… WEEK 1: Agent-level cost control configuration
# Set per-agent limits for token usage and cost
# Optional: All fields have sensible defaults if not specified

# Maximum tokens per API call (default: 1000 tokens)
max_tokens_per_call: 1000

# Maximum tokens per 24-hour period (default: 50,000 tokens/day)
max_tokens_per_day: 50000

# Maximum cost per 24-hour period in USD (default: $10/day)
max_cost_per_day: 10.0

# Alert threshold: warn when usage exceeds this % of daily limit (default: 0.80 = 80%)
# Range: 0.0 to 1.0
# E.g., 0.80 = warn when $8 spent out of $10 daily limit
cost_alert_threshold: 0.80

# Enforcement mode (default: false = warn only)
#   true  = BLOCK execution if limit exceeded (strict budget control)
#   false = WARN only (log warning but execute anyway)
enforce_cost_limits: false

system_prompt: |
  You are {{name}}.
  Role: {{role}}
  Description: {{description}}

  Backstory: {{backstory}}

  Be friendly, helpful, and concise in your responses.
