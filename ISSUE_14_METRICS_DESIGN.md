# üìä Issue #14: Metrics & Observability - Implementation Design

**Date**: 2025-12-22
**Status**: Design Phase
**Priority**: #1 (Highest)
**Effort**: 2-3 days

---

## üéØ Objective

Implement comprehensive metrics collection framework to provide production visibility into system performance, resource usage, and operational health.

---

## üìã Current State Analysis

### What Already Exists (from Issue #11)

```go
// ExecutionMetrics struct (crew.go:45-52)
type ExecutionMetrics struct {
    ToolName     string        // Tool name
    Duration     time.Duration // Execution time
    Status       string        // "success", "timeout", "error"
    TimedOut     bool          // Timeout flag
    StartTime    time.Time     // Start timestamp
    EndTime      time.Time     // End timestamp
}

// ToolTimeoutConfig (crew.go:55-72)
type ToolTimeoutConfig struct {
    DefaultToolTimeout  time.Duration
    SequenceTimeout     time.Duration
    PerToolTimeout      map[string]time.Duration
    CollectMetrics      bool                // Already has flag!
    ExecutionMetrics    []ExecutionMetrics  // Already collecting!
}
```

### Current Gaps

```
‚ùå No agent-level metrics
‚ùå No memory usage tracking
‚ùå No cache hit/miss tracking
‚ùå No request-level aggregation
‚ùå No metrics export format
‚ùå No metrics retrieval API
‚ùå No performance trending
```

---

## üèóÔ∏è Proposed Architecture

### Layer 1: Basic Metrics (Extend ExecutionMetrics)

```go
// Extended metrics with more detail
type ExtendedExecutionMetrics struct {
    // Existing fields
    ToolName      string
    Duration      time.Duration
    Status        string
    TimedOut      bool
    StartTime     time.Time
    EndTime       time.Time

    // NEW: Additional fields
    Success       bool          // true = success, false = error/timeout
    Error         string        // Error message if failed
    InputSize     int           // Size of input parameters
    OutputSize    int           // Size of output
    Retries       int           // Number of retry attempts
}
```

### Layer 2: Agent-Level Metrics

```go
// Agent execution metrics
type AgentMetrics struct {
    AgentID          string
    AgentName        string
    ExecutionCount   int64              // Total executions
    SuccessCount     int64              // Successful executions
    ErrorCount       int64              // Failed executions
    TimeoutCount     int64              // Timeout count

    // Duration stats
    TotalDuration    time.Duration      // Total time spent
    AverageDuration  time.Duration      // Average per execution
    MinDuration      time.Duration      // Fastest execution
    MaxDuration      time.Duration      // Slowest execution

    // Tool-level
    ToolMetrics      map[string]*ToolMetrics  // Per-tool stats
}

type ToolMetrics struct {
    ToolName         string
    ExecutionCount   int64
    SuccessCount     int64
    ErrorCount       int64
    AverageDuration  time.Duration
}
```

### Layer 3: System-Level Metrics

```go
// Overall system metrics
type SystemMetrics struct {
    StartTime              time.Time
    LastUpdated            time.Time

    // Request tracking
    TotalRequests          int64
    SuccessfulRequests     int64
    FailedRequests         int64

    // Timing
    TotalExecutionTime     time.Duration
    AverageRequestTime     time.Duration

    // Resource usage
    MemoryUsage            uint64  // Current memory
    MaxMemoryUsage         uint64  // Peak memory

    // Cache stats
    CacheHits              int64
    CacheMisses            int64
    CacheHitRate           float64

    // Agent stats (aggregated)
    AgentMetrics           map[string]*AgentMetrics
}
```

### Layer 4: Metrics Collector (Main Component)

```go
// MetricsCollector - thread-safe metrics aggregation
type MetricsCollector struct {
    mu                     sync.RWMutex
    systemMetrics          *SystemMetrics
    currentAgentMetrics    *AgentMetrics

    // Configuration
    CollectingEnabled      bool
    RecordMemory           bool

    // Helper
    startTime              time.Time
}

// Methods
func (mc *MetricsCollector) RecordToolExecution(toolName string, duration time.Duration, success bool)
func (mc *MetricsCollector) RecordAgentExecution(agentID string, agentName string, duration time.Duration, success bool)
func (mc *MetricsCollector) RecordCacheHit()
func (mc *MetricsCollector) RecordCacheMiss()
func (mc *MetricsCollector) UpdateMemoryUsage(current uint64)
func (mc *MetricsCollector) GetSystemMetrics() *SystemMetrics
func (mc *MetricsCollector) GetAgentMetrics(agentID string) *AgentMetrics
func (mc *MetricsCollector) ExportMetrics(format string) (string, error)  // JSON, Prometheus
func (mc *MetricsCollector) Reset()
```

---

## üìù Implementation Steps

### Step 1: Create Metrics Types (core/metrics.go - NEW FILE)

```go
package crewai

import (
    "sync"
    "time"
)

// ExtendedExecutionMetrics extends the ExecutionMetrics from Issue #11
type ExtendedExecutionMetrics struct {
    ToolName    string
    Duration    time.Duration
    Status      string
    TimedOut    bool
    Success     bool
    Error       string
    StartTime   time.Time
    EndTime     time.Time
}

// AgentMetrics tracks per-agent statistics
type AgentMetrics struct {
    AgentID        string
    AgentName      string
    ExecutionCount int64
    SuccessCount   int64
    ErrorCount     int64
    TimeoutCount   int64
    TotalDuration  time.Duration
    AverageDuration time.Duration
    ToolMetrics    map[string]*ToolMetrics
}

// ToolMetrics tracks per-tool statistics
type ToolMetrics struct {
    ToolName       string
    ExecutionCount int64
    SuccessCount   int64
    ErrorCount     int64
    AverageDuration time.Duration
}

// SystemMetrics aggregates all metrics
type SystemMetrics struct {
    StartTime           time.Time
    LastUpdated         time.Time
    TotalRequests       int64
    SuccessfulRequests  int64
    FailedRequests      int64
    TotalExecutionTime  time.Duration
    AverageRequestTime  time.Duration
    MemoryUsage         uint64
    MaxMemoryUsage      uint64
    CacheHits           int64
    CacheMisses         int64
    CacheHitRate        float64
    AgentMetrics        map[string]*AgentMetrics
}

// MetricsCollector collects and aggregates metrics
type MetricsCollector struct {
    mu                 sync.RWMutex
    systemMetrics      *SystemMetrics
    currentAgent       *AgentMetrics
    enabled            bool
}
```

### Step 2: Implement MetricsCollector Methods

```go
// NewMetricsCollector creates a new metrics collector
func NewMetricsCollector() *MetricsCollector {
    return &MetricsCollector{
        systemMetrics: &SystemMetrics{
            StartTime:    time.Now(),
            AgentMetrics: make(map[string]*AgentMetrics),
        },
        enabled: true,
    }
}

// RecordToolExecution records tool execution metrics
func (mc *MetricsCollector) RecordToolExecution(toolName string, duration time.Duration, success bool)

// RecordAgentExecution records agent execution metrics
func (mc *MetricsCollector) RecordAgentExecution(agentID, agentName string, duration time.Duration, success bool)

// RecordCacheHit records cache hit
func (mc *MetricsCollector) RecordCacheHit()

// GetSystemMetrics returns current system metrics
func (mc *MetricsCollector) GetSystemMetrics() *SystemMetrics

// ExportMetrics exports metrics in specified format
func (mc *MetricsCollector) ExportMetrics(format string) (string, error)
```

### Step 3: Integrate with CrewExecutor

Add to CrewExecutor:
```go
type CrewExecutor struct {
    // ... existing fields ...
    Metrics *MetricsCollector  // ‚Üê ADD THIS
}

// Initialize in NewCrewExecutor
executor.Metrics = NewMetricsCollector()

// Record metrics during ExecuteStream
func (ce *CrewExecutor) ExecuteStream(...) error {
    startTime := time.Now()
    success := true

    // ... execution logic ...

    ce.Metrics.RecordAgentExecution(
        agent.ID,
        agent.Name,
        time.Since(startTime),
        success,
    )
}
```

### Step 4: Add Metrics Export API

```go
// Add to http.go or new http_metrics.go

// MetricsHandler returns current metrics
func (h *HTTPHandler) MetricsHandler(w http.ResponseWriter, r *http.Request) {
    format := r.URL.Query().Get("format")  // "json" or "prometheus"
    if format == "" {
        format = "json"
    }

    metrics, err := h.executor.Metrics.ExportMetrics(format)
    if err != nil {
        http.Error(w, err.Error(), http.StatusInternalServerError)
        return
    }

    w.Header().Set("Content-Type", "application/json")
    w.Write([]byte(metrics))
}

// Register endpoint
http.HandleFunc("/metrics", handler.MetricsHandler)
```

---

## üß™ Test Coverage

### Test Cases (5-6 tests)

1. **TestMetricsCollectorCreation**
   - Verify collector initializes correctly
   - Check initial values

2. **TestRecordToolExecution**
   - Record tool execution
   - Verify metrics updated correctly
   - Check success/error counts

3. **TestRecordAgentExecution**
   - Record agent execution
   - Verify agent stats updated
   - Check duration calculations

4. **TestMetricsAggregation**
   - Record multiple executions
   - Verify aggregation (total, average)
   - Check min/max values

5. **TestMetricsExport**
   - Export to JSON format
   - Verify structure
   - Check data integrity

6. **TestCacheMetrics**
   - Record cache hits/misses
   - Verify hit rate calculation
   - Test zero-division case

---

## üìä Export Formats

### JSON Format Example

```json
{
  "system_metrics": {
    "start_time": "2025-12-22T10:00:00Z",
    "last_updated": "2025-12-22T10:05:00Z",
    "total_requests": 150,
    "successful_requests": 145,
    "failed_requests": 5,
    "total_execution_time": "2m30s",
    "average_request_time": "1s",
    "memory_usage_mb": 52,
    "max_memory_usage_mb": 56,
    "cache_hits": 1200,
    "cache_misses": 300,
    "cache_hit_rate": 0.80
  },
  "agent_metrics": {
    "researcher": {
      "agent_id": "researcher",
      "execution_count": 150,
      "success_count": 145,
      "error_count": 5,
      "total_duration": "2m30s",
      "average_duration": "1s",
      "tool_metrics": {
        "search_tool": {
          "execution_count": 300,
          "success_count": 290,
          "average_duration": "500ms"
        }
      }
    }
  }
}
```

### Prometheus Format Example

```prometheus
# HELP crew_requests_total Total number of requests processed
# TYPE crew_requests_total counter
crew_requests_total{status="success"} 145
crew_requests_total{status="error"} 5

# HELP crew_request_duration_seconds Request execution time
# TYPE crew_request_duration_seconds histogram
crew_request_duration_seconds_bucket{le="0.1"} 50
crew_request_duration_seconds_bucket{le="0.5"} 120
crew_request_duration_seconds_bucket{le="1"} 140

# HELP crew_cache_hits_total Total cache hits
# TYPE crew_cache_hits_total counter
crew_cache_hits_total 1200

# HELP crew_memory_usage_bytes Current memory usage
# TYPE crew_memory_usage_bytes gauge
crew_memory_usage_bytes 54525952
```

---

## üîå Integration Points

### 1. HTTP Handler Integration
```go
// In http.go
func (h *HTTPHandler) StreamHandler(w http.ResponseWriter, r *http.Request) {
    startTime := time.Now()
    // ... execution ...
    h.executor.Metrics.RecordAgentExecution(
        agent.ID,
        agent.Name,
        time.Since(startTime),
        success,
    )
}
```

### 2. Crew Executor Integration
```go
// In crew.go ExecuteStream
func (ce *CrewExecutor) ExecuteStream(...) {
    startTime := time.Now()
    // ... execution logic ...
    success := err == nil
    ce.Metrics.RecordAgentExecution(
        agent.ID,
        agent.Name,
        time.Since(startTime),
        success,
    )
}
```

### 3. Tool Execution Integration
```go
// In executeCalls
startTime := time.Now()
output, err := safeExecuteTool(toolCtx, tool, call.Arguments)
success := err == nil
ce.Metrics.RecordToolExecution(tool.Name, time.Since(startTime), success)
```

---

## üìà Success Criteria

- ‚úÖ MetricsCollector implemented with thread-safe operations
- ‚úÖ Agent-level metrics collected for all agents
- ‚úÖ Tool-level metrics collected for all tools
- ‚úÖ Memory usage tracking working
- ‚úÖ Cache hit/miss tracking functional
- ‚úÖ Metrics export to JSON format working
- ‚úÖ Metrics export to Prometheus format working
- ‚úÖ Metrics endpoint accessible via HTTP
- ‚úÖ 5-6 comprehensive test cases passing
- ‚úÖ Zero race conditions
- ‚úÖ Production-ready code

---

## üéØ Timeline

| Day | Task |
|-----|------|
| **Day 1** | Create metrics.go, implement types, basic collector |
| **Day 1.5** | Integrate with CrewExecutor, add HTTP handler |
| **Day 2** | Implement export formats (JSON, Prometheus) |
| **Day 2.5** | Write comprehensive tests |
| **Day 3** | Final testing, documentation, commit |

---

## ‚ö†Ô∏è Considerations

1. **Thread Safety**: RWMutex for metrics access
2. **Performance**: Minimal overhead for metric recording
3. **Memory**: Store reasonable history (e.g., last 1000 executions)
4. **Export Format**: Support both JSON and Prometheus
5. **Reset Capability**: Allow resetting metrics for testing

---

## üì¶ Deliverables

1. **core/metrics.go** - New file with all metrics types and collector
2. **core/crew.go** - Modified to integrate metrics collection
3. **core/http.go** - Added /metrics endpoint
4. **core/crew_test.go** - Added metrics tests
5. **Documentation** - Updated with metrics usage

---

**Status**: Ready for Implementation
**Next**: Begin with Step 1 - Create metrics types

